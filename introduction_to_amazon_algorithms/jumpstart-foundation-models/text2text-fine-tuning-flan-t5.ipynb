{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "362b27d1-cd77-46d7-88f0-68748156703d",
   "metadata": {},
   "source": [
    "Welcome to Amazon SageMaker JumpStart! You can use Sagemaker JumpStart to solve many Machine Learning tasks through one-click in SageMaker Studio, or through SageMaker Python SDK.\n",
    "\n",
    "In this demo notebook, we demonstrate how to fine-tune a pre-trained Large Language Model (LLM) using FLAN T5 XL model as an example.\n",
    "\n",
    "LLMs are pre-trained on a large corpus of text (e.g., crawl of the Internet), and often can perform a variety of natural language-related tasks out of the box. However, it has been observed that a task-specific fune-tuning (i.e., additional training) can further improve model performance on that particular task or language domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1706e56-3d74-4f2c-b5cd-695acca57d5c",
   "metadata": {},
   "source": [
    "Note: This notebook was tested on ml.t3.medium instance in Amazon SageMaker Studio with Python 3 (Data Science) kernel and in Amazon SageMaker Notebook ml.t3.medium instance with conda_python3 kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75888cd0-bc56-4a83-a1c3-a884b94d859b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: test in SM studio?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714a91ac-431d-4adc-8285-4e1dd73721d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "General setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c83140fe-f5d2-49ee-a433-70109cf23bd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "# SageMaker estimator and model instances will use this role\n",
    "aws_role = sagemaker.session.Session().get_caller_identity_arn()\n",
    "\n",
    "# We will store fine-tuned models in this S3 bucket\n",
    "output_bucket = sagemaker.Session().default_bucket()\n",
    "\n",
    "# This will be useful for printing\n",
    "newline, bold, unbold = \"\\n\", \"\\033[1m\", \"\\033[0m\"\n",
    "\n",
    "# We are using XL version of FLAN T5 in this demo\n",
    "model_size= \"xl\"\n",
    "\n",
    "# Demo results were obtained using this training instance\n",
    "training_instance_type = \"ml.p3.16xlarge\"\n",
    "num_training_gpus = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446e7d1c-5615-47dd-8ad7-e63b78ee7206",
   "metadata": {},
   "source": [
    "Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bbe5ed1-0594-4341-bb09-c1761bb38d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO this will be retrieved using SM API\n",
    "train_image_uri = \"763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-training:1.10.2-transformers4.17.0-gpu-py38-cu113-ubuntu20.04\"\n",
    "train_source_uri = \"./text2text\"\n",
    "\n",
    "if model_size == \"xl\":\n",
    "    # copied from s3://sagemaker-jumpstart-cache-contributor-staging/jumpstart-1p/text2text/training-huggingface-text2text-huggingface-text2text-flan-t5-xl-repack.tar.gz\n",
    "    train_model_uri = \"s3://sagemaker-us-west-2-802376408542/avkan/training-huggingface-text2text-huggingface-text2text-flan-t5-xl-repack.tar.gz\"\n",
    "elif model_size == \"base\":\n",
    "    # copied from s3://sagemaker-jumpstart-cache-contributor-staging/jumpstart-1p/text2text/infer-huggingface-text2text-flan-t5-base.tar.gz\n",
    "    train_model_uri = \"s3://sagemaker-us-west-2-802376408542/avkan/infer-huggingface-text2text-flan-t5-base.tar.gz\"\n",
    "else:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fb3bee5-3345-41bc-bfc0-7540fbec2872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO for faster trial, use dev data and 1 epoch (1 hour) / for demo we used train data and 3 epochs (5 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ed0df7c-0414-49d9-953d-1d48675236c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO what is the proper dataset path?\n",
    "data_channel = \"train\"\n",
    "training_dataset_s3_path = f\"s3://sagemaker-us-west-2-802376408542/data/SQuADv2/genuq/{data_channel}/\"\n",
    "\n",
    "output_location = f\"s3://{output_bucket}/demo-fine-tune-flan-t5/\"\n",
    "\n",
    "# TODO\n",
    "hyperparameters = {\n",
    "    \"epochs\": 3,                        # number of training epochs\n",
    "    \"learning_rate\": 1e-4,              # learning rate used during training\n",
    "    \"batch_size\": 8*num_training_gpus,  # (batch size per gpu) x (num gpus on training instance)\n",
    "    \"training_script\": \"train.py\",      # training script\n",
    "    # \"max_input_length\": 300,            # data inputs will be truncated at this length\n",
    "    # \"max_output_length\": 40,           # data outputs will be truncated at this length\n",
    "    # \"generation_max_length\": 40,       # max length of generated output\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdf3377-4cd7-40df-876b-e0fa2f57dc8f",
   "metadata": {},
   "source": [
    "Training job will take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "068d6c5a-00a1-48d0-a2cd-86bcdd15cb0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mmodel uri:\u001b[0m s3://sagemaker-us-west-2-802376408542/avkan/training-huggingface-text2text-huggingface-text2text-flan-t5-xl-repack.tar.gz\n",
      "\u001b[1mjob name:\u001b[0m jumpstart-demo-xl-3-2023-04-06-08-16-42-738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: jumpstart-demo-xl-3-2023-04-06-08-16-42-738\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "training_job_name = name_from_base(f\"jumpstart-demo-{model_size}-{hyperparameters['epochs']}\")\n",
    "\n",
    "# TODO check how are these used\n",
    "training_metric_definitions = [\n",
    "    {\"Name\": \"val_loss\", \"Regex\": \"'eval_loss': ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"train_loss\", \"Regex\": \"'loss': ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"epoch\", \"Regex\": \"'epoch': ([0-9\\\\.]+)\"},\n",
    "]\n",
    "\n",
    "print(f\"{bold}model uri:{unbold} {train_model_uri}\")\n",
    "print(f\"{bold}job name:{unbold} {training_job_name}\")\n",
    "\n",
    "# Create SageMaker Estimator instance\n",
    "sm_estimator = Estimator(\n",
    "    role=aws_role,\n",
    "    image_uri=train_image_uri,\n",
    "    source_dir=train_source_uri,\n",
    "    model_uri=train_model_uri,\n",
    "    entry_point=\"transfer_learning.py\",\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    volume_size=300,\n",
    "    max_run=360000,\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=output_location,\n",
    "    metric_definitions=training_metric_definitions,\n",
    ")\n",
    "\n",
    "# Launch a SageMaker training job over data located in the given S3 path\n",
    "# Training jobs can take hours, it is recommended to set wait=False,\n",
    "# and monitor job status through SageMaker console\n",
    "sm_estimator.fit(\n",
    "    {\"training\": training_dataset_s3_path},\n",
    "    job_name=training_job_name,\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629eaa2c-b415-4bd7-b8bc-500f118862e5",
   "metadata": {},
   "source": [
    "Remainder of the notebook should be executed once the training job is successfully completed. Variable, `training_job_name` should contain job name. `output_location` should point to an S3 location with a fine-tuned model artifact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e809c7-4772-4d5c-957b-b3f2e1f85b76",
   "metadata": {},
   "source": [
    "We will create two inference endpoints, one for the original pre-trained model, and one for the fine-tuned model. We will then run the same request agains the two endpoints and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0e2263f-a733-45fa-81b8-6e3e2cd765b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preparing for model inference\n",
    "model_id, model_version = f\"huggingface-text2text-flan-t5-{model_size}\", \"*\"\n",
    "inference_instance_type = \"ml.p3.2xlarge\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004ae06a-6f40-4544-8602-a3eb072d6237",
   "metadata": {},
   "source": [
    "Each endpoint deployment can take a few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c37e490b-2c5e-493d-a3f8-03345742f994",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import image_uris\n",
    "\n",
    "# Retrieve the inference docker image URI. This is the base HuggingFace container image\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,  # automatically inferred from model_id\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    image_scope=\"inference\",\n",
    "    instance_type=inference_instance_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "487a9d26-11fa-4788-a768-2535060b0aa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: jumpstart-demo-pre-trained-huggingface--2023-04-06-15-23-00-516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mimage URI:\u001b[0m\n",
      " 763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-inference:1.10.2-transformers4.17.0-gpu-py38-cu113-ubuntu20.04\n",
      "\u001b[1mmodel URI:\u001b[0m\n",
      " s3://jumpstart-cache-prod-us-west-2/huggingface-infer/infer-huggingface-text2text-flan-t5-xl.tar.gz\n",
      "Deploying an endpoint ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating endpoint-config with name jumpstart-demo-pre-trained-huggingface--2023-04-06-15-23-00-516\n",
      "INFO:sagemaker:Creating endpoint with name jumpstart-demo-pre-trained-huggingface--2023-04-06-15-23-00-516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------!\n",
      "Deployed an endpoint jumpstart-demo-pre-trained-huggingface--2023-04-06-15-23-00-516\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import model_uris\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "# Retrieve the URI of the pre-trained model\n",
    "pre_trained_model_uri = model_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, model_scope=\"inference\"\n",
    ")\n",
    "\n",
    "pre_trained_name = name_from_base(f\"jumpstart-demo-pre-trained-{model_id}\")\n",
    "\n",
    "# TODO comment on repacking\n",
    "# TODO no repacking for smaller models?\n",
    "\n",
    "# Create the SageMaker model instance of the pre-trained model\n",
    "pre_trained_model = Model(\n",
    "    image_uri=deploy_image_uri,\n",
    "    model_data=pre_trained_model_uri,\n",
    "    role=aws_role,\n",
    "    predictor_cls=Predictor,\n",
    "    name=pre_trained_name,\n",
    ")\n",
    "\n",
    "print(f\"{bold}image URI:{unbold}{newline} {deploy_image_uri}\")\n",
    "print(f\"{bold}model URI:{unbold}{newline} {pre_trained_model_uri}\")\n",
    "print(\"Deploying an endpoint ...\")\n",
    "\n",
    "# Deploy the pre-trained model. Note that we need to pass Predictor class when we deploy model\n",
    "# through Model class, for being able to run inference through the sagemaker API\n",
    "pre_trained_predictor = pre_trained_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    predictor_cls=Predictor,\n",
    "    endpoint_name=pre_trained_name,\n",
    "    volume_size=30,\n",
    ")\n",
    "print(f\"{newline}Deployed an endpoint {pre_trained_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07cab2be-f433-41c3-bee5-e8e0d61a7a91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: jumpstart-demo-fine-tuned-huggingface-t-2023-04-06-15-29-03-700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mimage URI:\u001b[0m\n",
      " 763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-inference:1.10.2-transformers4.17.0-gpu-py38-cu113-ubuntu20.04\n",
      "\u001b[1mmodel URI:\u001b[0m\n",
      " s3://sagemaker-us-west-2-802376408542/demo-fine-tune-flan-t5/jumpstart-demo-xl-3-2023-04-06-08-16-42-738/output/model.tar.gz\n",
      "Deploying an endpoint ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating endpoint-config with name jumpstart-demo-fine-tuned-huggingface-t-2023-04-06-15-29-03-700\n",
      "INFO:sagemaker:Creating endpoint with name jumpstart-demo-fine-tuned-huggingface-t-2023-04-06-15-29-03-700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!\n",
      "Deployed an endpoint jumpstart-demo-fine-tuned-huggingface-t-2023-04-06-15-29-03-700\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "fine_tuned_name = name_from_base(f\"jumpstart-demo-fine-tuned-{model_id}\")\n",
    "fine_tuned_model_uri = f\"{output_location}{training_job_name}/output/model.tar.gz\"\n",
    "\n",
    "# Create the SageMaker model instance of the fine-tuned model\n",
    "fine_tuned_model = Model(\n",
    "    image_uri=deploy_image_uri,\n",
    "    model_data=fine_tuned_model_uri,\n",
    "    role=aws_role,\n",
    "    predictor_cls=Predictor,\n",
    "    name=fine_tuned_name,\n",
    ")\n",
    "\n",
    "print(f\"{bold}image URI:{unbold}{newline} {deploy_image_uri}\")\n",
    "print(f\"{bold}model URI:{unbold}{newline} {fine_tuned_model_uri}\")\n",
    "print(\"Deploying an endpoint ...\")\n",
    "\n",
    "# Deploy the fine-tuned model.\n",
    "fine_tuned_predictor = fine_tuned_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    predictor_cls=Predictor,\n",
    "    endpoint_name=fine_tuned_name,\n",
    "    volume_size=30,\n",
    ")\n",
    "print(f\"{newline}Deployed an endpoint {fine_tuned_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb2f1f73-4ba9-422a-adf1-d94a686c2b70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Helper functions for running inference queries\n",
    "def query_endpoint_with_json_payload(payload, endpoint_name):\n",
    "    encoded_json = json.dumps(payload).encode(\"utf-8\")\n",
    "    client = boto3.client(\"runtime.sagemaker\")\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, ContentType=\"application/json\", Body=encoded_json\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def parse_response_multiple_texts(query_response):\n",
    "    model_predictions = json.loads(query_response[\"Body\"].read())\n",
    "    generated_text = model_predictions[\"generated_texts\"]\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2598072e-fc52-40c0-8343-1a74e35cfa3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_paragraphs = [\n",
    "\"\"\"\n",
    "Adelaide is the capital city of South Australia, the state's largest city and the fifth-most populous city in Australia.\n",
    "\"Adelaide\" may refer to either Greater Adelaide (including the Adelaide Hills) or the Adelaide city centre.\n",
    "The demonym Adelaidean is used to denote the city and the residents of Adelaide. The Traditional Owners of the Adelaide\n",
    "region are the Kaurna people. The area of the city centre and surrounding parklands is called Tarndanya in the Kaurna language.\n",
    "\n",
    "Adelaide is situated on the Adelaide Plains north of the Fleurieu Peninsula, between the Gulf St Vincent in the west and\n",
    "the Mount Lofty Ranges in the east. Its metropolitan area extends 20 km (12 mi) from the coast to the foothills of\n",
    "the Mount Lofty Ranges, and stretches 96 km (60 mi) from Gawler in the north to Sellicks Beach in the south.\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "Amazon Elastic Block Store (Amazon EBS) provides block level storage volumes for use with EC2 instances. EBS volumes behave like raw, unformatted block devices. You can mount these volumes as devices on your instances. EBS volumes that are attached to an instance are exposed as storage volumes that persist independently from the life of the instance. You can create a file system on top of these volumes, or use them in any way you would use a block device (such as a hard drive). You can dynamically change the configuration of a volume attached to an instance.\n",
    "\n",
    "We recommend Amazon EBS for data that must be quickly accessible and requires long-term persistence. EBS volumes are particularly well-suited for use as the primary storage for file systems, databases, or for any applications that require fine granular updates and access to raw, unformatted, block-level storage. Amazon EBS is well suited to both database-style applications that rely on random reads and writes, and to throughput-intensive applications that perform long, continuous reads and writes.\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "Amazon Comprehend uses natural language processing (NLP) to extract insights about the content of documents. It develops insights by recognizing the entities, key phrases, language, sentiments, and other common elements in a document. Use Amazon Comprehend to create new products based on understanding the structure of documents. For example, using Amazon Comprehend you can search social networking feeds for mentions of products or scan an entire document repository for key phrases. \n",
    "You can access Amazon Comprehend document analysis capabilities using the Amazon Comprehend console or using the Amazon Comprehend APIs. You can run real-time analysis for small workloads or you can start asynchronous analysis jobs for large document sets. You can use the pre-trained models that Amazon Comprehend provides, or you can train your own custom models for classification and entity recognition. \n",
    "All of the Amazon Comprehend features accept UTF-8 text documents as the input. In addition, custom classification and custom entity recognition accept image files, PDF files, and Word files as input. \n",
    "Amazon Comprehend can examine and analyze documents in a variety of languages, depending on the specific feature. For more information, see Languages supported in Amazon Comprehend. Amazon Comprehend's Dominant language capability can examine documents and determine the dominant language for a far wider selection of languages.\n",
    "\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1009a072-4a6e-4e5f-93eb-ccdd3732c784",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"Ask a question which is related to the following text, but cannot be answered based on the text. Text: {context}\"\n",
    "\n",
    "# TODO\n",
    "parameters = {\n",
    "    \"max_length\": 30,           # restrict the length of the answer\n",
    "    \"num_return_sequences\": 3,\n",
    "    \"num_beams\": 10,\n",
    "    # \"seed\": 1, # 42, #146,                # for reproducibility\n",
    "    # \"do_sample\": True,\n",
    "    # \"top_k\": 50,\n",
    "    # \"top_p\": 0.95,\n",
    "    # \"temperature\": 1.3,\n",
    "}\n",
    "\n",
    "def generate_questions(endpoint_name, text):\n",
    "    expanded_prompt = prompt.replace(\"{context}\", text)\n",
    "    payload = {\"text_inputs\": expanded_prompt, **parameters}\n",
    "    query_response = query_endpoint_with_json_payload(payload, endpoint_name=endpoint_name)\n",
    "    generated_texts = parse_response_multiple_texts(query_response)\n",
    "    for i, generated_text in enumerate(generated_texts):\n",
    "        print(f\"Response {i}: {generated_text}{newline}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42d04ea2-82a0-446a-b64d-ab68442081a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPrompt:\u001b[0m 'Ask a question which is related to the following text, but cannot be answered based on the text. Text: {context}'\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Adelaide is the capital city of South Australia, the state's largest city and the fifth-most populous city in Australia.\n",
      "\"Adelaide\" may refer to either Greater Adelaide (including the Adelaide Hills) or the Adelaide city centre.\n",
      "The demonym Adelaidean is used to denote the city and the residents of Adelaide. The Traditional Owners of the Adelaide\n",
      "region are the Kaurna people. The area of the city centre and surrounding parklands is called Tarndanya in the Kaurna language.\n",
      "\n",
      "Adelaide is situated on the Adelaide Plains north of the Fleurieu Peninsula, between the Gulf St Vincent in the west and\n",
      "the Mount Lofty Ranges in the east. Its metropolitan area extends 20 km (12 mi) from the coast to the foothills of\n",
      "the Mount Lofty Ranges, and stretches 96 km (60 mi) from Gawler in the north to Sellicks Beach in the south.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[1mpre-trained\u001b[0m\n",
      "Response 0: What is the area of the city centre and surrounding parklands called in the Kaurna language?\n",
      "\n",
      "Response 1: What is the area of the city centre and surrounding parklands is called Tarndanya in the Kaurna language?\n",
      "\n",
      "Response 2: What is the area of the city centre and surrounding parklands called in Kaurna?\n",
      "\n",
      "\u001b[1mfine-tuned\u001b[0m\n",
      "Response 0: What is the second most populous city in Australia?\n",
      "\n",
      "Response 1: What is the fourth most populous city in Australia?\n",
      "\n",
      "Response 2: What is the population of Gawler?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Amazon Elastic Block Store (Amazon EBS) provides block level storage volumes for use with EC2 instances. EBS volumes behave like raw, unformatted block devices. You can mount these volumes as devices on your instances. EBS volumes that are attached to an instance are exposed as storage volumes that persist independently from the life of the instance. You can create a file system on top of these volumes, or use them in any way you would use a block device (such as a hard drive). You can dynamically change the configuration of a volume attached to an instance.\n",
      "\n",
      "We recommend Amazon EBS for data that must be quickly accessible and requires long-term persistence. EBS volumes are particularly well-suited for use as the primary storage for file systems, databases, or for any applications that require fine granular updates and access to raw, unformatted, block-level storage. Amazon EBS is well suited to both database-style applications that rely on random reads and writes, and to throughput-intensive applications that perform long, continuous reads and writes.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[1mpre-trained\u001b[0m\n",
      "Response 0: What is the difference between Amazon EBS and Amazon Elastic Block Store (Amazon EBS)?\n",
      "\n",
      "Response 1: What is the difference between Amazon EBS and Amazon Elastic Block Store?\n",
      "\n",
      "Response 2: What is the difference between Amazon EBS and Amazon Simple Storage Service (Amazon S3)?\n",
      "\n",
      "\u001b[1mfine-tuned\u001b[0m\n",
      "Response 0: What type of applications are not well suited to Amazon EBS?\n",
      "\n",
      "Response 1: What behaves like formatted block devices?\n",
      "\n",
      "Response 2: What type of applications are not suited to Amazon EBS?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Amazon Comprehend uses natural language processing (NLP) to extract insights about the content of documents. It develops insights by recognizing the entities, key phrases, language, sentiments, and other common elements in a document. Use Amazon Comprehend to create new products based on understanding the structure of documents. For example, using Amazon Comprehend you can search social networking feeds for mentions of products or scan an entire document repository for key phrases. \n",
      "You can access Amazon Comprehend document analysis capabilities using the Amazon Comprehend console or using the Amazon Comprehend APIs. You can run real-time analysis for small workloads or you can start asynchronous analysis jobs for large document sets. You can use the pre-trained models that Amazon Comprehend provides, or you can train your own custom models for classification and entity recognition. \n",
      "All of the Amazon Comprehend features accept UTF-8 text documents as the input. In addition, custom classification and custom entity recognition accept image files, PDF files, and Word files as input. \n",
      "Amazon Comprehend can examine and analyze documents in a variety of languages, depending on the specific feature. For more information, see Languages supported in Amazon Comprehend. Amazon Comprehend's Dominant language capability can examine documents and determine the dominant language for a far wider selection of languages.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[1mpre-trained\u001b[0m\n",
      "Response 0: What does Amazon Comprehend use to extract insights about the content of documents?\n",
      "\n",
      "Response 1: How does Amazon Comprehend extract insights about the content of documents?\n",
      "\n",
      "Response 2: What does Amazon Comprehend use to develop insights about the content of documents?\n",
      "\n",
      "\u001b[1mfine-tuned\u001b[0m\n",
      "Response 0: What does Amazon Comprehend use to extract insights about the structure of documents?\n",
      "\n",
      "Response 1: How does Amazon Comprehend recognize sentiments in a document?\n",
      "\n",
      "Response 2: What does Amazon Comprehend use to extract insights about the content of social networking feeds?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"{bold}Prompt:{unbold} {repr(prompt)}\")\n",
    "for paragraph in test_paragraphs:\n",
    "    print(\"-\" * 80)\n",
    "    print(paragraph)\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{bold}pre-trained{unbold}\")\n",
    "    generate_questions(pre_trained_name, paragraph)\n",
    "    print(f\"{bold}fine-tuned{unbold}\")\n",
    "    generate_questions(fine_tuned_name, paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99076e38-16db-4b77-9545-d21796af4ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete resources\n",
    "pre_trained_predictor.delete_model()\n",
    "pre_trained_predictor.delete_endpoint()\n",
    "fine_tuned_predictor.delete_model()\n",
    "fine_tuned_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bf201f-3cbd-4123-b49b-cc837e31b70c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
